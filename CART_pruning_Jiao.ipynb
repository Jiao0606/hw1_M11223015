{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b9d8df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65d65474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 匯入資料\n",
    "columns_name = ['age','workclass','fnlwgt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','income']\n",
    "\n",
    "data_train = pd.read_csv('adult.data', names=columns_name, header=None)\n",
    "df_train = pd.DataFrame(data_train)\n",
    "\n",
    "data_test = pd.read_csv('adult.test', names=columns_name, skiprows=1, header=None)\n",
    "df_test = pd.DataFrame(data_test)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# missing value\n",
    "columns_to_check = ['workclass', 'occupation', 'native-country']\n",
    "\n",
    "df_train.replace(\" ?\", np.nan, inplace=True)\n",
    "column_modes = df_train[columns_to_check].mode().iloc[0]\n",
    "df_train.fillna(column_modes, inplace=True)\n",
    "\n",
    "df_test.replace(\" ?\", np.nan, inplace=True)\n",
    "column_modes = df_test[columns_to_check].mode().iloc[0]\n",
    "df_test.fillna(column_modes, inplace=True)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 將 income 轉換為 int64 (>50K:1；<=50K:0)\n",
    "\n",
    "df_train.replace(\" >50K\", 1, inplace = True)\n",
    "df_train.replace(\" <=50K\", 0, inplace = True)\n",
    "\n",
    "df_test.replace(\" >50K.\", 1, inplace = True)\n",
    "df_test.replace(\" <=50K.\", 0, inplace = True)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Outlier\n",
    "\n",
    "def detect_and_handle_Outlier(df, column_name, treshold=1.5):\n",
    "    #IQR = Q3-Q1\n",
    "    IQR = np.percentile(df[column_name],75) - np.percentile(df[column_name],25)\n",
    "    #upper_outlier = Q3 + treshold*IQR \n",
    "    df=df[df[column_name] < np.percentile(df[column_name],75)+treshold*IQR]\n",
    "    #lower_outlier = Q1 - treshold*IQR \n",
    "    df=df[df[column_name] > np.percentile(df[column_name],25)-treshold*IQR]\n",
    "    return df\n",
    "\n",
    "columns_to_check = ['age','education-num','hours-per-week','income']\n",
    "\n",
    "for column in columns_to_check:\n",
    "    df_train = detect_and_handle_Outlier(df_train, column)\n",
    "    \n",
    "for column in columns_to_check:\n",
    "    df_test = detect_and_handle_Outlier(df_test, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe62d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# combine train and test data\n",
    "df_data = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 移除無關屬性的欄位\n",
    "# df_data.describe()\n",
    "df_data.drop('fnlwgt', axis = 1, inplace = True)\n",
    "df_data.drop('capital-gain', axis = 1, inplace = True)\n",
    "df_data.drop('capital-loss', axis = 1, inplace = True)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# One Hot Encoding\n",
    "df_data = pd.get_dummies(df_data)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# split train and test data\n",
    "df_train = df_data[:len(df_train)]\n",
    "df_test = df_data[len(df_train):]\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# split feature and class\n",
    "train_x = df_train.drop('income', axis=1)\n",
    "train_y = df_train['income']\n",
    "\n",
    "test_x = df_test.drop('income', axis=1)\n",
    "test_y = df_test['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a281280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 建立模型 CART\n",
    "model = tree.DecisionTreeClassifier()\n",
    "\n",
    "def CART_model(depth, leaf, top):\n",
    "    # ---------------------------------------------------\n",
    "    # 建立模型 CART\n",
    "    model = tree.DecisionTreeClassifier(max_depth=depth, min_samples_leaf=leaf)\n",
    "\n",
    "    # 訓練\n",
    "    model.fit(train_x, train_y)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 預測、評估模型好壞\n",
    "    train_pred = model.predict(train_x)\n",
    "\n",
    "    # 輸出混淆矩陣，顯示準確率\n",
    "    print(\"Train: 輸出混淆矩陣，顯示準確率\")\n",
    "    print('====================================================================')\n",
    "    print(confusion_matrix(train_y, train_pred))\n",
    "    print(classification_report(train_y, train_pred))\n",
    "\n",
    "    train_result = df_train[['income']].copy()\n",
    "    train_result['predict'] = train_pred\n",
    "\n",
    "    # train_result.to_excel('CART_train_result.xlsx', index=False)\n",
    "\n",
    "\n",
    "    #預測，評估模型好壞\n",
    "    test_pred = model.predict(test_x)\n",
    "\n",
    "    #輸出混淆矩陣，顯示準確率：使用測試資料\n",
    "    print(\"Test: 輸出混淆矩陣，顯示準確率\")\n",
    "    print('====================================================================')\n",
    "    print(confusion_matrix(test_y, test_pred))\n",
    "    print(classification_report(test_y, test_pred))\n",
    "\n",
    "    test_result = df_test[['income']].copy()\n",
    "    test_result['predict'] = test_pred\n",
    "\n",
    "    # test_result.to_excel('CART_test_result.xlsx', index=False)\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------\n",
    "    # ROC\n",
    "\n",
    "    #將預測結果與真實資料 合併成 DataFrame\n",
    "    from pandas import DataFrame\n",
    "    df_PredResult = DataFrame({\"Pred\": test_pred, \"Real\":test_y})\n",
    "\n",
    "\n",
    "    #將預測結果與真實資料 合併成DataFrame\n",
    "    from pandas import DataFrame\n",
    "    df_PredProb = DataFrame(model.predict_proba(test_x))\n",
    "    df_myResult = pd.concat([df_PredResult, df_PredProb], axis=1)\n",
    "\n",
    "\n",
    "    #Compute ROC curve and ROC area for each class\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    import matplotlib.pyplot as plt\n",
    "    fpr,tpr,threshold = roc_curve(test_y, test_pred)\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "    print(\"ROC_auc area=%.4f\" % (roc_auc))\n",
    "\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # PRC\n",
    "\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    lr_precision, lr_recall, _ = precision_recall_curve(test_y, test_pred)\n",
    "\n",
    "    from sklearn.metrics import f1_score\n",
    "    lr_fl, lr_auc = f1_score(test_y, test_pred), auc(lr_recall, lr_precision)\n",
    "    print(\"PRC_auc area=%.4f\" % (lr_auc))\n",
    "    \n",
    "    # ---------------------------------------------------\n",
    "    # 模型輸出，精緻圖形\n",
    "    import graphviz\n",
    "    dot_data = tree.export_graphviz(\n",
    "                model, # (決策樹模型)\n",
    "                out_file= None,\n",
    "                feature_names= test_x.columns,\n",
    "                filled= True,\n",
    "                impurity= False,\n",
    "                rounded= True\n",
    "            )\n",
    "    \n",
    "    graph = graphviz.Source(dot_data) #選擇可視化的dot數據\n",
    "    graph.format = 'png'\n",
    "    \n",
    "    \n",
    "    graph.render('Top ' + str(top) + ' CART Dtree.gv')\n",
    "    \n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # decision tree image\n",
    "    import matplotlib.image as mpimg # mpimg 用於讀取圖片\n",
    "\n",
    "    lena = mpimg.imread('Top ' + str(top) + ' CART Dtree.gv.png') #讀取和程式碼處於同一目錄下的 lena.png\n",
    "    # 此時 lena 就已經是一個 np.array 了，可以對它進行任意處理\n",
    "    lena.shape #(512, 512, 3)\n",
    "    plt.imshow(lena) #顯示圖片\n",
    "    plt.axis('off') #不顯示座標軸\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc31ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# grid search\n",
    "param_grid = [\n",
    "{'min_samples_leaf': range(1, 30), 'max_depth': range(1, 30)},\n",
    "]\n",
    " \n",
    "grid_search = GridSearchCV(model, param_grid, scoring='accuracy', cv=5)\n",
    " \n",
    "grid_search.fit(test_x, test_y)\n",
    "\n",
    "# 取得所有參數組合的評估績效\n",
    "results = grid_search.cv_results_\n",
    "mean_test_accuracy = results['mean_test_score']\n",
    "\n",
    "# 排序 accuracy，找到 Top3 的 accuracy\n",
    "top_k = 3\n",
    "sorted_indices = np.argsort(mean_test_accuracy)[::-1][:top_k]\n",
    "results = grid_search.cv_results_\n",
    "mean_test_accuracy = results['mean_test_score']\n",
    "\n",
    "# 排序 accuracy，找到 Top3 的 accuracy\n",
    "top_k = 3\n",
    "sorted_indices = np.argsort(mean_test_accuracy)[::-1][:top_k]\n",
    "\n",
    "# 取得 Top3 的參數組合和 mean accuracy\n",
    "top_k_params = [results['params'][i] for i in sorted_indices]\n",
    "top_k_scores = [mean_test_accuracy[i] for i in sorted_indices]\n",
    "\n",
    "for i in range(top_k):\n",
    "    print(f\"Rank {i + 1}: {top_k_params[i]}, Mean Test Accuracy: {top_k_scores[i]}\")\n",
    "    CART_model(top_k_params[i]['max_depth'],top_k_params[i]['min_samples_leaf'], i+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
